{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXIUTZxHURfpD8KiN9G/YX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kanyinsola-O/CE888/blob/main/Lab8/Lab8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Ao0Y_GCv2w"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "from random import shuffle\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import xception\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PwSQj2NDpQi"
      },
      "source": [
        "data_dir = os.listdir(\"data\") #data has manually been unzipped\n",
        "\n",
        "def make_folders_train(type):\n",
        "    '''Makes folders for trainining and test sets\n",
        "        makes folder per species '''\n",
        "    path = f'visual_data/{type}_images'\n",
        "    if not os.path.isdir(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "    classes = [f'dogs_{type}', f'cats_{type}',\n",
        "               f'horses_{type}', f'humans_{type}']\n",
        "    for c in classes:\n",
        "        p = os.path.join(path, c)\n",
        "        if not os.path.isdir(p):\n",
        "            os.mkdir(p)\n",
        "\n",
        "\n",
        "types = ['train', 'test']\n",
        "for type in types:\n",
        "    make_folders_train(type)\n",
        "\n",
        "\n",
        "def create_sets(size=0.9):\n",
        "    #puts training images , split according to size parameters,store in its respective folders\n",
        "    for f in data_dir:\n",
        "        path = os.path.join('data', f)\n",
        "        imgs = os.listdir(path)\n",
        "        split_set = int(len(imgs) * size)\n",
        "\n",
        "        test = imgs[split_set:]\n",
        "        train = imgs[:split_set]\n",
        "        for img_test in test:\n",
        "            test_path = os.path.join(\n",
        "                'visual_data\\\\test_images\\\\' + f.lower() + '_test', img_test)\n",
        "            img_test = os.path.join(path, img_test)\n",
        "\n",
        "            shutil.copyfile(img_test, test_path)\n",
        "\n",
        "        for img_train in train:\n",
        "            train_path = os.path.join(\n",
        "                'visual_data\\\\train_images\\\\' + f.lower() + '_train', img_train)\n",
        "            img_train = os.path.join(path, img_train)\n",
        "            shutil.copyfile(img_train, train_path)\n",
        "\n",
        "\n",
        "create_sets()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxyfd4ebDsal"
      },
      "source": [
        "print('-' * 60)\n",
        "print(\"Test Data\")\n",
        "p = 'visual_data\\\\test_images'\n",
        "for f in os.listdir(p):\n",
        "    print(f'{f} {len(os.listdir(os.path.join(p, f)))}')\n",
        "print('-' * 60)\n",
        "print(\"Train Data\")\n",
        "p = 'visual_data\\\\train_images'\n",
        "for f in os.listdir(p):\n",
        "    print(f'{f} {len(os.listdir(os.path.join(p, f)))}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBt4jvv2EgXj"
      },
      "source": [
        "IMG_SIZE= 224\n",
        "img_input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "#Data augmentation\n",
        "train_gen = ImageDataGenerator(rescale=1.0/255,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    horizontal_flip = True)\n",
        "\n",
        "val_gen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "#Train set generator\n",
        "train_generator = train_gen.flow_from_directory(\n",
        "    \"visual_data\\\\train_images\",\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical')\n",
        "#validation set generator\n",
        "val_generator = val_gen.flow_from_directory(\n",
        "    \"visual_data\\\\test_images\",\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhISxWdaEmFq"
      },
      "source": [
        "model = xception.Xception(include_top=True, weights='imagenet',\n",
        "                          input_tensor=img_input, classes=1000, classifier_activation='softmax')\n",
        "model.summary()\n",
        "\n",
        "last_layer = model.get_layer('avg_pool').output\n",
        "out = Dense(4, activation='softmax', name='output')(last_layer)\n",
        "model = Model(img_input, out)\n",
        "for layer in model.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam', metrics=[\n",
        "              'accuracy'], loss='categorical_crossentropy')\n",
        "\n",
        "my_callbacks = [\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath='xception_model.h5', save_best_only=True),\n",
        "]\n",
        "\n",
        "history = model.fit_generator(train_generator, epochs=20, validation_data=val_generator, callbacks=my_callbacks )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4JAmBRrEn5y"
      },
      "source": [
        "def plot_curve(metric, save=False, saveas='test'):\n",
        "    '''Plots the learning curve for the model\n",
        "    based on history, metric takes any acceptable metric\n",
        "    by the model e.g. Loss, if save is set to true\n",
        "    saves a copy of the graph under the name specified\n",
        "    in saveas by default is test'''\n",
        "    plt.plot(history.history[metric], label=f'{metric} in training set')\n",
        "    plt.plot(history.history[f'val_{metric}'],\n",
        "             label=f'{metric} in validation set')\n",
        "    plt.title(metric)\n",
        "    plt.ylabel('Value')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "    if save:\n",
        "        plt.savefig(f'{saveas}')\n",
        "    plt.show()\n",
        "import matplotlib.pyplot as plt\n",
        "plot_curve('loss')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}